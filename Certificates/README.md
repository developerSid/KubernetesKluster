# Certs for the cluster

## Tools
1. [cfssl](https://cfssl.org)
   1. need `cfssl` and `cfssljson`

## Cert Generation for the Vagrant based steps
1. change directory to /Certificates/vagrant

### Create the certificate authority.
All the certificates and keys used throughout this setup will use the CA generated here as their base
1. If you choose to generate them yourself
   1. The basics of the following files can be generated by
      1. `cfssl print-defaults config > ca-config.json`
      1. `cfssl print-defaults config > ca-csr.json`
1. Otherwise
1. Generate you Certificate Authority (CA)
   1. `cd out`
   1. `cfssl gencert -initca ../in/ca-csr.json | cfssljson -bare ca -`
      * You should be able to use what is already in the _ca-config.json_, but you can always change it if you want
      1. Will result in
         * ca.csr - this is not used anywhere according to the etcd documentation
         * ca.pem
         * ca-key.pem

### Create the peer certificates using the newly created CA
1. Generate the encryption-config.yml for the API server
   1. `../in/encryption-config.sh`
1. Will need to update the _ca-csr.json_ with your locality's information
1. Generate etcd certificates
   1. For the 3 node cluster defined with the vagrant configuration these instructions will generate 3 sets of keys
   1. `cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=../in/ca-config.json -profile=etcd ../in/master01-etcd.vagrant.example-server.json | cfssljson -bare master01-etcd.vagrant.example`
      1. Generates:
         * master01.vagrant.example.csr
         * master01.vagrant.example.pem
         * master01.vagrant.example-key.pem
   1. `cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=../in/ca-config.json -profile=etcd ../in/master02-etcd.vagrant.example-server.json | cfssljson -bare master02-etcd.vagrant.example`
      1. Generates:
         * master02.vagrant.example.csr
         * master02.vagrant.example.pem
         * master02.vagrant.example-key.pem
   1. `cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=../in/ca-config.json -profile=etcd ../in/master03-etcd.vagrant.example-server.json | cfssljson -bare master03-etcd.vagrant.example`
      1. Generates:
         * master02.vagrant.example.csr
         * master02.vagrant.example.pem
         * master02.vagrant.example-key.pem
                 
### Create Kubernetes certificates and keys
1. Generate the shared master certificates
   1. `cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=../in/ca-config.json -profile=kubernetes ../in/master.vagrant.example-server.json | cfssljson -bare master.vagrant.example`
      1. Results in
         * master.vagrant.example.csr
         * master.vagrant.example.pem
         * master.vagrant.example-key.pem
   1. Notes: 
      1. The hosts section defines the load balancer which will be used as one of the hosts as it will be the entry
         point to the cluster.  This allows for the cluster control plane to be dynamic.
         1. From the Heptio article: <br>
            _"Kubernetes automatically creates a service named Kubernetes in the default namespaces, 
            that is kubernetes.default according to the internal DNS notation; this service provides 
            a well-known, portable, in-cluster way that pods can use to access the APIserver."_
            
            _"The Kubernetes Service is assigned the first address in the service address space 
            defined by --service-cluster-ip-range flag of the kube-apiserver"_ 
            
            Based on the IP Addressing scheme borrowed from _Kubernetes the Hard Way_ that address chosen from the
            _--service-cluster-ip-range_ flag it would be 10.32.0.1 (Note: one of the steps will be setting up HAProxy 
            on each master node to route requests to that node's api server instance)
         ```json
         "hosts": [
             "192.168.50.10",
             "127.0.0.1",
             "10.32.0.1",
             "kubernetes.default"
           ]
         ```
1. Generate the Service Account Key Pair
   1. `cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=../in/ca-config.json -profile=kubernetes ../in/service-account-csr.json | cfssljson -bare service-account`
      1. Will Result in
         * service-account.csr
         * service-account.pem
         * service-account-key.pem
1. Generate the kube-controller-manager Key Pair
   1. `cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=../in/ca-config.json -profile=kubernetes ../in/kube-controller-manager-csr.json | cfssljson -bare kube-controller-manager`
      1. Will Result in
         * kube-controller-manager.csr
         * kube-controller-manager.pem
         * kube-controller-manager-key.pem
1. Generate the kube-scheduler Key Pair
   1. `cfssl gencert -ca=ca.pem  -ca-key=ca-key.pem  -config=../in/ca-config.json  -profile=kubernetes ../in/kube-scheduler-csr.json | cfssljson -bare kube-scheduler`
      1. Will Result in
         * kube-scheduler.csr
         * kube-scheduler.pem
         * kube-scheduler-key.pem
1. Generate the admin Key Pair
   1. `cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=../in/ca-config.json -profile=kubernetes ../in/admin-csr.json | cfssljson -bare admin`
      1. Will Result in
         * admin.csr
         * admin.pem
         * admin-key.pem

### Create the kubelet certificates and keys
For the vagrant based example there are only 2 worker nodes since it is intended to run from a single machine so only 2 signing requests have
been created.  To create more just add more _worker*-csr.json_ files.

* Make sure to set the hosts section appropriately

1. Generate worker01 Key Pair
   1. `cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=../in/ca-config.json -profile=kubernetes ../in/worker01-csr.json | cfssljson -bare worker01.vagrant.example`
      1. Will Result in
         * worker01.csr
         * worker01.pem
         * worker01-key.pem
1. Generate worker02 Key Pair
   1. `cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=../in/ca-config.json -profile=kubernetes ../in/worker02-csr.json | cfssljson -bare worker02.vagrant.example`
      1. Will Result in
         * worker02.csr
         * worker02.pem
         * worker02-key.pem
1. Very important note the O in the workerX-csr.json needs to be *"O": "system:nodes",*
         
Notes:
1. [api server certs doc](https://kubernetes.io/docs/reference/access-authn-authz/authentication/#x509-client-certs)
   * _If a client certificate is presented and verified, the common name of the subject is 
     used as the user name for the request_
     * The above means that each client cert generated for each kubelet running in the system will
       need to have a unique common name to help name the actual node.  This must be why in
       Kubernetes the Hard Way certs are generated for each node.  Since the CA determines
       if a client is trusted or not.